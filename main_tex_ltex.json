{"disabledRules":[],"langs":["zh-CN"],"hiddenFalsePositives":{"zh-CN":["{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q可以有效的解决此问题。\\\\E$\"}","{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q深度强化学习解决方案通常需要巨大的计算资源来训练和泛化，\\\\E$\"}","{\"rule\":\"wa5\",\"sentence\":\"^\\\\Q而从前一状态经过随机进入下一状态的过程被称为状态转移。\\\\E$\"}","{\"rule\":\"wa5\",\"sentence\":\"^\\\\Q所以本文中考虑使用线性二次最优控制问题。\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q等式左边为价值函数处于时间步\\\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\\\Q时对于价值的估计，\\\\E$\"}","{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q并介绍借由此开发的两种新的强化学习算法来解决上述的问题。\\\\E$\"}","{\"rule\":\"wa5\",\"sentence\":\"^\\\\QKoopman张量估计\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q代理在每个时间步获得与该时间步的策略熵成比例的奖金。\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q\\\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\\\Q更改为包括除了第一个时间步以外的每个时间步的熵奖励：\\\\E$\"}","{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q可以期望其得到更精准的预测。\\\\E$\"}","{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q我们就可以保留成本函数的形式进行进一步的控制。\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q我们可以很容易地通过前馈网络预测未来的\\\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\\\Q步状态。\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q然后K步预测如下：\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\QK步损失函数.\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q这种方法仅用于单步预测。\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q并设计了用于长期预测的K步预测损失函数。\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\QK步损失不是只考虑下面的一步预测误差，\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q而是关注K步预测误差的加权和，\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q在做单步预测时，\\\\E$\"}","{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q并且取两个矩阵的和作为新的升维状态，\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q四种算法在Lorenz系统中每2000步回报曲线图\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q前4000步随机探索，\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q2000步回报\\\\E$\"}","{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q使得智能体在强非线性系统中有比较好的表现。\\\\E$\"}","{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q算法展现了比较好的表现，\\\\E$\"}","{\"rule\":\"wb4\",\"sentence\":\"^\\\\Q且无法实现真正的端到端的训练。\\\\E$\"}","{\"rule\":\"wa5\",\"sentence\":\"^\\\\QKoopman算子可以用最小二乘法自动学习系统模型。\\\\E$\"}","{\"rule\":\"BU\",\"sentence\":\"^\\\\Q分两步提出了深度Koopman算子辅助的最大熵强化学习算法，\\\\E$\"}"]}}